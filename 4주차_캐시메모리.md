# 캐시 메모리
속도가 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리를 말한다.
- CPU 캐시 메모리, 웹 브라우저 캐시, 디스크 캐시...

# CPU 캐시 메모리
## 왜 사용할까?
느림 < 속도 < 빠름
CPU         메모리
- CPU는 상대적으로 빠르고 , 메모리는 상대적으로 속도가 느리다.
- CPU는 빠르게 일처리를 마치고 있는데, 메모리가 느려서 이 일에 필요한 데이터를 넘기는 속도를 맞추지 못해 발생하는 문제(병목 현상)을 해결하기 위해 사용하는 것이 캐시메모리.

## 캐시에 사용되는 메모리의 종류

- DRAM : 주로 축전기로 작동한다.(스스로 방전 -> 데이터가 변화함 -> 지속적으로 충전을 해주어야한다.)
    - 장점 : 가격이 싸고 부피가 작다.
    - 단점 : 속도가 느리다.
현세대 기준으로 DRAM을 주기억장치로 사용한다.
-SRAM : 주로 플립플롭으로 작동한다.(전류 신호가 오기전까지는 상태가 변화하지 않는 소자이다.)
    - 장점 : SRAM은 속도는 빠르다.
    - 단점 : 가격이 매우 비싸고 부피가 크다.
현세대 기준으로 SRAM이 캐시 메모리로 사용한다.
CPU와 DRAM 사이에 SRAM을 별도로 두어서 DRAM의 데이터를 직접 접근하는 것보다는 빠르게 접근할 수 있도록 한다

## CPU가 메모리에 접근하는 횟수를 줄여 성능을 향상하는 방법
![image](https://user-images.githubusercontent.com/80687913/203764203-e4dad642-3084-474f-9106-df0ff4a6086a.png)
CPU가 주기억장치에서 저장된 데이터를 읽어올 때, 자주 사용하는 데이터를 캐시 메모리에 저장하고, 다음부터는 캐시 메모리에서 먼저 가져옴으로써 속도를 향상시킨다.
- 자주 사용하는 데이터를 CPU와 더 가까운 캐시 메모리에 저장.

- L1 : CPU 내부에 존재
- L2 : CPU와 RAM 사이에 존재
- L3 : 보통 메인보드에 존재한다고 함

찾고자 하는 데이터가 캐시메모리에서 발견 시(hit) 해당 data를 바로 참조하고, 없을 경우(miss) 주기억 장치에 접근한다.
히트율 : hit 수 / CPU에 의한 메모리 참조 수(주기억장치 포함) 입니다.
참조국한성 : 프로그램이 수행되는 동안 메모리 참조는 국한된 영역에서만 이루어진다. 
참조국한성에 의해 일반적으로 0.9

## 작동 원리
데이터 지역성
- 시간 지역성
한번 참조된 데이터는 잠시후 또 참조될 가능성이 높다.
ex. 반복문에서 사용하는 조건 변수
- 공간 지역성
참조된 데이터 근처에 있는 데이터가 잠시후 또 사용될 가능성이 높다.
ex. 배열의 각 요소와 같이 연속된 데이터

## 캐시 미스 종류
- Cold miss
해당 메모리 주소를 처음 불러서 나는 미스
- Conflict miss
A라는 데이터와 B라는 데이터가 같은 캐시 메모리 주소에 할당되어 있다고 가정.
추후, 데이터를 가져오기 위해 해당 캐시 메모리 주소를 참조했을 때 원하는 데이터가 없어서 나는 미스
- Capacity miss
캐시 메모리의 공간이 부족해서 나는 미스
캐시 크기를 키워서 해결하려면 값도 비싸지고 속도가 느려지고 전력을 많이 사용하게 됨.

## 캐시 구조
- Direct Mapped Cache
![](https://aidanbae.github.io/code/devops/computer/cpucache/screenshot3.png)
> DRAM의 여러개 주소가 캐시메모리의 한 주소에 대응되는 다대일(n:1)방식

캐시 메모리 공간이 8개 (000₂부터 111₂)
메모리 공간이 32개 (00000₂부터 11111₂)

00001₂, 01001₂, 10001₂, 11001₂인 곳의 데이터를 캐시 메모리의 주소가 001₂인 곳에만 읽고 쓰는 방식이다.

이때 000₂이 '인덱스 필드', 인덱스 제외한 앞의 나머지(00₂, 01₂, 10₂, 11₂)를 '태그 필드'라고 한다.

이처럼 캐시메모리는 인덱스 필드 + 태그 필드 + 데이터 필드로 구성된다.

간단하고 빠른 장점이 있지만, Conflict Miss가 발생하는 것이 단점이다. 위 사진처럼 같은 색깔의 데이터를 동시에 사용해야 할 때 발생한다.

- Fully Associative Cache
쉽게 설명하면 비어있는 캐시메모리가 있으면 그냥 마음대로 주소를 저장하는 방식. 즉 저장시 크게 알고리즘 비용이 없어 간단한데, 찾을 때 문제. 모든 블럭을 순회해 데이터가 있는지 검사. 이를 위해 CAM(content Addressable memory)라는 특수한 형태의 메모리 구조를 사용하는데 가격이 비싸다.

- Set Associative Cache
Direct Mapping과 Associative가 종합 한 방식. 특정 행을 지정해서 그 행안의 어떤 열이든 비어있으면 저장. DMC에 비해 검색은 오래걸리지만 저장이 빠르며 Associative에 비해 저장이 느리지만 검색이 빠른 중간형.

현대 잘나간다는 cpu 캐시들은 대부분 이방식을 취하고 있다.



[참고한 사이트]
- https://aidanbae.github.io/code/devops/computer/cpucache/
